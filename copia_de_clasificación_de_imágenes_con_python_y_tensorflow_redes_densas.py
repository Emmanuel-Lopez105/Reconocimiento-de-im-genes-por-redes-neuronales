# -*- coding: utf-8 -*-
# """Copia de Clasificación de imágenes con Python y Tensorflow - Redes Densas

# Automatically generated by Colab.

# Original file is located at
#    https://colab.research.google.com/drive/1Tz3bEUfOXy0N5_DhVklhP40t4kAJXI4J
#"""


# Importar las bibliotecas TensorFlow y TensorFlow Datasets.
# TensorFlow es usado para construir y entrenar redes neuronales.
# TensorFlow Datasets provee conjuntos de datos predefinidos listos para usar.
import tensorflow as tf
import tensorflow_datasets as tfds

# Descargar el conjunto de datos "fashion_mnist".
# Incluye 70,000 imágenes en escala de grises (28x28 píxeles) de ropa y accesorios en 10 categorías.
# `as_supervised=True` devuelve tuplas (imagen, etiqueta).
# `with_info=True` incluye información adicional del conjunto de datos como tamaño y clases.
datos, metadatos = tfds.load('fashion_mnist', as_supervised=True, with_info=True)

# Explorar la información del conjunto de datos para verificar las clases disponibles, tamaño, etc.
metadatos

# Separar los datos en conjuntos de entrenamiento y pruebas.
# `datos['train']` contiene 60,000 imágenes de entrenamiento.
# `datos['test']` contiene 10,000 imágenes de prueba.
datos_entrenamiento, datos_pruebas = datos['train'], datos['test']

# Obtener los nombres de las 10 categorías de ropa (por ejemplo, 'camiseta', 'zapatos').
nombres_clases = metadatos.features['label'].names  # Esto devuelve una lista de nombres de las etiquetas.
nombres_clases  # Verificar los nombres de las clases.

# Normalización de imágenes: Convertir valores de píxeles de 0-255 a 0-1 para mejorar el entrenamiento.
def normalizar(imagenes, etiquetas):
    """
    Normaliza los valores de los píxeles de la imagen.
    - Convierte los valores de 0-255 a 0-1.
    - Deja las etiquetas sin cambios.
    """
    imagenes = tf.cast(imagenes, tf.float32)  # Convertir a tipo float32 para cálculos de red neuronal.
    imagenes /= 255  # Dividir cada valor de píxel entre 255.
    return imagenes, etiquetas

# Aplicar la función de normalización a los conjuntos de datos de entrenamiento y prueba.
datos_entrenamiento = datos_entrenamiento.map(normalizar)  # Mapear la función `normalizar` sobre los datos.
datos_pruebas = datos_pruebas.map(normalizar)

# Cachear los datos preprocesados para evitar realizar las mismas operaciones repetidamente.
# Esto mejora la velocidad durante el entrenamiento y pruebas.
datos_entrenamiento = datos_entrenamiento.cache()
datos_pruebas = datos_pruebas.cache()

# Mostrar una imagen del conjunto de datos para verificar su preprocesamiento.
# `take(1)` selecciona un lote de una sola imagen para mostrar.
for imagen, etiqueta in datos_entrenamiento.take(1):
    break
imagen = imagen.numpy().reshape((28, 28))  # Convertir la imagen a una matriz 2D para visualización.

# Dibujar la imagen usando Matplotlib.
import matplotlib.pyplot as plt
plt.figure()  # Crear una figura.
plt.imshow(imagen, cmap=plt.cm.binary)  # Mostrar la imagen en escala de grises.
plt.colorbar()  # Agregar una barra de colores para indicar valores de píxeles.
plt.grid(False)  # Deshabilitar la cuadrícula para claridad.
plt.show()  # Mostrar la imagen.

# Mostrar 25 imágenes con sus etiquetas correspondientes.
# Iterar sobre los primeros 25 ejemplos del conjunto de entrenamiento.
plt.figure(figsize=(10, 10))  # Ajustar el tamaño de la figura.
for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):
    imagen = imagen.numpy().reshape((28, 28))  # Convertir cada imagen a matriz 2D.
    plt.subplot(5, 5, i + 1)  # Crear un subgrafico 5x5.
    plt.xticks([])  # Quitar las marcas en el eje X.
    plt.yticks([])  # Quitar las marcas en el eje Y.
    plt.grid(False)  # Deshabilitar la cuadrícula.
    plt.imshow(imagen, cmap=plt.cm.binary)  # Mostrar la imagen.
    plt.xlabel(nombres_clases[etiqueta])  # Etiquetar la imagen con su categoría.
plt.show()  # Mostrar todas las imágenes.

# Crear un modelo de red neuronal con Keras.
# El modelo tiene:
# - Una capa de entrada que aplana imágenes de 28x28 a 1D.
# - Dos capas ocultas densas con 50 neuronas cada una y activación ReLU.
# - Una capa de salida con 10 neuronas (una para cada clase) y activación Softmax.
modelo = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),  # Convertir imagen 2D a 1D.
    tf.keras.layers.Dense(50, activation=tf.nn.relu),  # Primera capa oculta.
    tf.keras.layers.Dense(50, activation=tf.nn.relu),  # Segunda capa oculta.
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)  # Capa de salida.
])

# Compilar el modelo.
# - Optimizador Adam para ajustar los pesos de la red.
# - Función de pérdida categórica cruzada para medir el error en clasificación.
# - Métrica de precisión para evaluar el rendimiento.
modelo.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

# Obtener el número de ejemplos en los conjuntos de entrenamiento y pruebas.
num_ej_entrenamiento = metadatos.splits["train"].num_examples
num_ej_pruebas = metadatos.splits["test"].num_examples

print(num_ej_entrenamiento)  # Imprimir 60,000 imágenes de entrenamiento.
print(num_ej_pruebas)  # Imprimir 10,000 imágenes de prueba.

# Configurar el tamaño del lote para dividir los datos en fragmentos más pequeños durante el entrenamiento.
TAMANO_LOTE = 32

# Mezclar y agrupar datos de entrenamiento y pruebas en lotes.
# `repeat()` permite repetir los datos indefinidamente (útil para múltiples épocas).
# `shuffle()` reorganiza los datos para reducir el sesgo.
datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE)
datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)

import math

# Entrenar el modelo durante 5 épocas (pasadas completas por los datos de entrenamiento).
# `steps_per_epoch` indica cuántos lotes de entrenamiento usar por época.
historial = modelo.fit(datos_entrenamiento, epochs=5, steps_per_epoch=math.ceil(num_ej_entrenamiento / TAMANO_LOTE))

# Graficar la pérdida durante el entrenamiento para observar cómo mejora el modelo.
plt.xlabel("# Época")  # Etiqueta del eje X.
plt.ylabel("Magnitud de pérdida")  # Etiqueta del eje Y.
plt.plot(historial.history["loss"])  # Graficar la pérdida por cada época.

# Obtener predicciones del modelo sobre un lote de datos de prueba.
for imagenes_prueba, etiquetas_prueba in datos_pruebas.take(1):  # Tomar un lote de prueba.
    imagenes_prueba = imagenes_prueba.numpy()  # Convertir las imágenes a Numpy.
    etiquetas_prueba = etiquetas_prueba.numpy()  # Convertir las etiquetas a Numpy.
    predicciones = modelo.predict(imagenes_prueba)  # Realizar predicciones.

# Definir funciones para graficar imágenes y resultados de predicciones.
# Estas funciones ayudan a interpretar los resultados del modelo.
